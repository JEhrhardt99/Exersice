#| label: setwd
#| echo: true
#| output: false
# set working directory to script location
if (requireNamespace("rstudioapi", quietly = TRUE) && rstudioapi::isAvailable()) {
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}
# check if wd is the root directory
getwd()
#| label: read_day_1
#| echo: true
#| output: false
# move up to project root and read data from data subfolder
df <- fread("../Data/Tankerkoenig/prices/2021/01/2021-01-01-prices.csv")
#| label: correct_date
#| echo: true
#| output: false
# first, the date varaible is not correctly read and needs to be corrected to German time zone:
# Convert the 'date' column to POSIXct and handle time zone
df$date <- as.POSIXct(df$date,
format = "%Y-%m-%d %H:%M:%S%z",
tz = "Europe/Berlin")
#| label: active_stations
#| echo: true
#| output: true
# How many stations were active on that day?
unique(df$station_uuid) %>% length()
# Show variable types
str(df)
# show if there are any missing values
colSums(is.na(df))
# summary statistics
summary(df)
#| label: investigate_data
#| echo: true
#| output: true
# create histogram of distribution of diesel prices
ggplot(df, aes(x = diesel)) +
geom_histogram(bins = 50, fill = "blue", color = "black") +
labs(title = "Distribution of Diesel Prices",
x = "Price in Euro",
y = "Frequency") +
theme_few()
# create histogram of distribution of e10 prices
ggplot(df, aes(x = e10)) +
geom_histogram(bins = 50, fill = "blue", color = "black") +
labs(title = "Distribution of E10 Prices",
x = "Price in Euro",
y = "Frequency") +
theme_few()
View(df)
# Chunk 1: load packages
#| label: load packages
#| echo: true
#| output: false
library(ggplot2)
library(ggthemes)
library(data.table)
library(tidyverse)
# Chunk 2: setwd
#| label: setwd
#| echo: true
#| output: false
# set working directory to script location
if (requireNamespace("rstudioapi", quietly = TRUE) && rstudioapi::isAvailable()) {
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}
# check if wd is the root directory
getwd()
# Chunk 3: read_day_1
#| label: read_day_1
#| echo: true
#| output: false
# move up to project root and read data from data subfolder
df <- fread("../Data/Tankerkoenig/prices/2021/01/2021-01-01-prices.csv")
# Chunk 4: correct_date
#| label: correct_date
#| echo: true
#| output: false
# first, the date varaible is not correctly read and needs to be corrected to German time zone:
# Convert the 'date' column to POSIXct and handle time zone
df$date <- as.POSIXct(df$date,
format = "%Y-%m-%d %H:%M:%S%z",
tz = "Europe/Berlin")
# Chunk 5: active_stations
#| label: active_stations
#| echo: true
#| output: true
# How many stations were active on that day?
unique(df$station_uuid) %>% length()
# Show variable types
str(df)
# show if there are any missing values
colSums(is.na(df))
# summary statistics
summary(df)
#| label: investigate_data
#| echo: true
#| output: true
# create histogram of distribution of diesel prices
ggplot(df, aes(x = diesel)) +
geom_histogram(bins = 50, fill = "blue", color = "black") +
labs(title = "Distribution of Diesel Prices",
x = "Price in Euro",
y = "Frequency") +
theme_few()
# create histogram of distribution of e10 prices
ggplot(df, aes(x = e10)) +
geom_histogram(bins = 50, fill = "blue", color = "black") +
labs(title = "Distribution of E10 Prices",
x = "Price in Euro",
y = "Frequency") +
theme_few()
#| label: investigate_weird_prices
#| echo: true
#| output: true
# subset the weird observations
weird_obs <- df %>% filter(diesel == -0.001 |
e10 == -0.001)
head(weird_obs, 3)
View(weird_obs)
#| label: daily_avg
#| echo: true
#| output: true
# Extract date only
unique_date <- as.Date(df$date[1],
tz = "Europe/Berlin")
# Group by station_uuid to calculate daily averages, and add the extracted unique date as a column
daily_averages <- df[, .(
avg_diesel = mean(diesel),
avg_e5 = mean(e5),
avg_e10 = mean(e10)
), by = station_uuid][, date_only := unique_date]
# View the result
head(daily_averages,
3)
# count the number of observations of daily_averages
nrow(daily_averages)
# should be the same as the number of unique station_uuids
unique(df$station_uuid) %>% length()
#| label: save_data
#| echo: true
#| output: false
getwd()
# Specify the subfolder
subfolder <- "../Data/Tankerkoenig/prices_avg"
# save unique date as string to name the saved .csv like that
unique_date_str <- as.character(unique_date)
# Define the full file path including filename
file_path <- file.path(subfolder, paste0(unique_date_str, "-avg-price-station.csv"))
# Save the DataFrame to CSV
write.csv(daily_averages,
file = file_path,
row.names = FALSE,
fileEncoding = "UTF-8")
#| label: test1
#| echo: true
#| output: true
test <- fread(paste0("../Data/Tankerkoenig/prices_avg/", unique_date_str, "-avg-price-station.csv"))
str(test)
head(test, 3)
View(test)
View(df)
View(daily_averages)
# Chunk 1: load_packages
#| label: load_packages
#| echo: true
#| output: false
library(ggplot2)
library(ggthemes)
library(data.table)
library(tidyverse)
# Chunk 2: setwd
#| label: setwd
#| echo: true
#| output: false
# set working directory to script location
if (requireNamespace("rstudioapi", quietly = TRUE) && rstudioapi::isAvailable()) {
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}
# check if wd is the root directory
getwd()
# Chunk 3: read_day_1
#| label: read_day_1
#| echo: true
#| output: false
# move up to project root and read data from data subfolder
df <- fread("../Data/Tankerkoenig/prices/2021/01/2021-01-01-prices.csv")
# Chunk 4: correct_date
#| label: correct_date
#| echo: true
#| output: false
# first, the date varaible is not correctly read and needs to be corrected to German time zone:
# Convert the 'date' column to POSIXct and handle time zone
df$date <- as.POSIXct(df$date,
format = "%Y-%m-%d %H:%M:%S%z",
tz = "Europe/Berlin")
# Chunk 5: active_stations
#| label: active_stations
#| echo: true
#| output: true
# How many stations were active on that day?
unique(df$station_uuid) %>% length()
# Show variable types
str(df)
# show if there are any missing values
colSums(is.na(df))
# summary statistics
summary(df)
# Chunk 6: investigate_data
#| label: investigate_data
#| echo: true
#| output: true
# create histogram of distribution of diesel prices
ggplot(df, aes(x = diesel)) +
geom_histogram(bins = 50, fill = "blue", color = "black") +
labs(title = "Distribution of Diesel Prices",
x = "Price in Euro",
y = "Frequency") +
theme_few()
# create histogram of distribution of e10 prices
ggplot(df, aes(x = e10)) +
geom_histogram(bins = 50, fill = "blue", color = "black") +
labs(title = "Distribution of E10 Prices",
x = "Price in Euro",
y = "Frequency") +
theme_few()
# Chunk 7: investigate_weird_prices
#| label: investigate_weird_prices
#| echo: true
#| output: true
# subset the weird observations
weird_obs <- df %>% filter(diesel == -0.001 |
e10 == -0.001)
head(weird_obs, 3)
# Chunk 8: daily_avg
#| label: daily_avg
#| echo: true
#| output: true
# Extract date only
unique_date <- as.Date(df$date[1],
tz = "Europe/Berlin")
# Group by station_uuid to calculate daily averages, and add the extracted unique date as a column
daily_averages <- df[, .(
avg_diesel = mean(diesel),
avg_e5 = mean(e5),
avg_e10 = mean(e10)
), by = station_uuid][, date_only := unique_date]
# View the result
head(daily_averages,
3)
# count the number of observations of daily_averages
nrow(daily_averages)
# should be the same as the number of unique station_uuids
unique(df$station_uuid) %>% length()
getwd()
# Specify the subfolder
subfolder <- "../Data/Tankerkoenig/prices_avg"
unique_date_str <- as.character(unique_date)
# Define the full file path including filename
file_path <- file.path(subfolder, paste0(unique_date_str, "-avg-price-station.csv"))
# Save the DataFrame to CSV
write.csv(daily_averages,
file = file_path,
row.names = FALSE,
fileEncoding = "UTF-8")
# Chunk 1: load_packages
#| label: load_packages
#| echo: true
#| output: false
library(ggplot2)
library(ggthemes)
library(data.table)
library(tidyverse)
# Chunk 2: setwd
#| label: setwd
#| echo: true
#| output: false
# set working directory to script location
if (requireNamespace("rstudioapi", quietly = TRUE) && rstudioapi::isAvailable()) {
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}
# check if wd is the root directory
getwd()
# Chunk 3: read_day_1
#| label: read_day_1
#| echo: true
#| output: false
# move up to project root and read data from data subfolder
df <- fread("../Data/Tankerkoenig/prices/2021/01/2021-01-01-prices.csv")
# Chunk 4: correct_date
#| label: correct_date
#| echo: true
#| output: false
# first, the date varaible is not correctly read and needs to be corrected to German time zone:
# Convert the 'date' column to POSIXct and handle time zone
df$date <- as.POSIXct(df$date,
format = "%Y-%m-%d %H:%M:%S%z",
tz = "Europe/Berlin")
# Chunk 5: active_stations
#| label: active_stations
#| echo: true
#| output: true
# How many stations were active on that day?
unique(df$station_uuid) %>% length()
# Show variable types
str(df)
# show if there are any missing values
colSums(is.na(df))
# summary statistics
summary(df)
# Chunk 6: investigate_data
#| label: investigate_data
#| echo: true
#| output: true
# create histogram of distribution of diesel prices
ggplot(df, aes(x = diesel)) +
geom_histogram(bins = 50, fill = "blue", color = "black") +
labs(title = "Distribution of Diesel Prices",
x = "Price in Euro",
y = "Frequency") +
theme_few()
# create histogram of distribution of e10 prices
ggplot(df, aes(x = e10)) +
geom_histogram(bins = 50, fill = "blue", color = "black") +
labs(title = "Distribution of E10 Prices",
x = "Price in Euro",
y = "Frequency") +
theme_few()
# Chunk 7: investigate_weird_prices
#| label: investigate_weird_prices
#| echo: true
#| output: true
# subset the weird observations
weird_obs <- df %>% filter(diesel == -0.001 |
e10 == -0.001)
head(weird_obs, 3)
# Chunk 8: daily_avg
#| label: daily_avg
#| echo: true
#| output: true
# Extract date only
unique_date <- as.Date(df$date[1],
tz = "Europe/Berlin")
# Group by station_uuid to calculate daily averages, and add the extracted unique date as a column
daily_averages <- df[, .(
avg_diesel = mean(diesel),
avg_e5 = mean(e5),
avg_e10 = mean(e10)
), by = station_uuid][, date_only := unique_date]
# View the result
head(daily_averages,
3)
# count the number of observations of daily_averages
nrow(daily_averages)
# should be the same as the number of unique station_uuids
unique(df$station_uuid) %>% length()
getwd()
# Specify the subfolder
subfolder <- "../Data/Tankerkoenig/prices_avg"
unique_date_str <- as.character(unique_date)
# Define the full file path including filename
file_path <- file.path(subfolder, paste0(unique_date_str, "-avg-price-station.csv.gz"))
# now do the same using the fwrite function:
fwrite(daily_averages,
file = file_path,
row.names = FALSE)
test1 <- fread(paste0("../Data/Tankerkoenig/prices_avg/", unique_date_str, "-avg-price-station.csv.gz"))
View(test1)
# now do the same using the fwrite function, since this is more efficient
fwrite(daily_averages,
file = file_path,
row.names = FALSE)
test1 <- fread(paste0("../Data/Tankerkoenig/prices_avg/", unique_date_str, "-avg-price-station.csv.gz"))
str(test)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory to script location
setwd("../..") # move up to the project root directory
getwd() # check if wd is the root directory
air_usa <- read_csv("main/Data_sets/air-usa.csv")
is.Date(air_usa$time)
air_usa <- air_usa %>%
mutate(year= str_sub(time,1, 4),
month=str_sub(time, 6)
)%>%
mutate(date= as.Date(paste("01", month, year, sep = "-"),
format("%d-%m-%Y")))
is.Date(air_usa$date)
#is it time series
is.ts(air_usa)
#change to time series
air_usa_ts <- ts(air_usa$pas, start= c(1996,1), frequency = 12)
is.ts(air_usa_ts)
plot(air_usa$date,air_usa$pas,typ="l")
ts.plot(air_usa_ts)
plot_raw <- ggplot(air_usa, aes(x=date, y=pas)) +
geom_line() +
labs(title="Number of Passengers",
x="Date",
y="Passengers"
)
plot_raw
ggsave("pass.png")
plot_tl <- ggplot(air_usa, aes(x=date, y=pas))+
geom_line()+
geom_smooth(
aes(color="Trendline"),
method = "lm_robust",
se= FALSE,
linewidth= 0.5
)+
labs(title="Number of Passengers",
x="Date",
y="Passengers"
)
plot_tl
layout(1:2)
#load packages------------------------
library("haven")
library("Hmisc")
library("expss")
library("dplyr")
library("ggplot2")
library("tidyverse")
library("readr")
install.packages("forecast")
library(forecast)
library(lubridate)
library(zoo)
library(xts)
library(gridExtra)
install.packages("estimatr")
air_usa <- read_csv("main/Data_sets/air-usa.csv")
is.Date(air_usa$time)
air_usa <- air_usa %>%
mutate(year= str_sub(time,1, 4),
month=str_sub(time, 6)
)%>%
mutate(date= as.Date(paste("01", month, year, sep = "-"),
format("%d-%m-%Y")))
is.Date(air_usa$date)
#is it time series
is.ts(air_usa)
#change to time series
air_usa_ts <- ts(air_usa$pas, start= c(1996,1), frequency = 12)
is.ts(air_usa_ts)
plot(air_usa$date,air_usa$pas,typ="l")
ts.plot(air_usa_ts)
plot_raw <- ggplot(air_usa, aes(x=date, y=pas)) +
geom_line() +
labs(title="Number of Passengers",
x="Date",
y="Passengers"
)
plot_raw
ggsave("pass.png")
plot_tl <- ggplot(air_usa, aes(x=date, y=pas))+
geom_line()+
geom_smooth(
aes(color="Trendline"),
method = "lm_robust",
se= FALSE,
linewidth= 0.5
)+
labs(title="Number of Passengers",
x="Date",
y="Passengers"
)
plot_tl
# install.packages("estimatr")
library(estimatr)
plot_tl <- ggplot(air_usa, aes(x=date, y=pas))+
geom_line()+
geom_smooth(
aes(color="Trendline"),
method = "lm_robust",
se= FALSE,
linewidth= 0.5
)+
labs(title="Number of Passengers",
x="Date",
y="Passengers"
)
plot_tl
layout(1:2)
plot(aggregate(air_usa_ts))
boxplot(air_usa_ts ~ cycle(air_usa_ts))
air_decom <- decompose(air_usa_ts, type = "multiplicative")
plot(air_decom)
air_decom <- decompose(air_usa_ts, type = "multiplicative")
plot(air_decom)
air_usa <- air_usa%>%
mutate(t=row_number())
reg_ols <- lm_robust(pas~t, data=air_usa)
summary(reg_ols)
msummary(reg_ols,
stars= c("*"=0.1,"**"=0.05, "***"=0.01),
fmt = "%.3f"
)
modelsummary(reg_ols,
stars= c("*"=0.1,"**"=0.05, "***"=0.01),
fmt = "%.3f"
)
modelsummary(reg_ols,
stars= c("*"=0.1,"**"=0.05, "***"=0.01),
fmt = "%.3f"
)
library(modelsummary)
library(modelsummary)
modelsummary(reg_ols,
stars= c("*"=0.1,"**"=0.05, "***"=0.01),
fmt = "%.3f"
)
